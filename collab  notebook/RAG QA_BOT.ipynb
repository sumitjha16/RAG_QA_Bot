{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOlpAgM2AORpUTYDRhWf+K0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Retrieval-Augmented Generation (RAG) Model for QA Bot**"],"metadata":{"id":"ZwG1QUfLM49e"}},{"cell_type":"markdown","source":["# **Installing Required Libraries**\n","\n","This cell installs all the necessary Python libraries required for the RAG (Retrieval-Augmented Generation) QA Bot. Here's a breakdown of each library:\n","\n","\n","* langchain: A framework for working with language models to build more advanced NLP applications.\n","* langchain_community: An extension of LangChain that includes community-driven features.\n","* langchain_core: Core components of LangChain to support LLM-powered applications.\n","* chromadb: A vector database that stores embeddings, which are useful for retrieving relevant documents.\n","*sentence_transformers: A library to generate sentence embeddings, useful for comparing and retrieving text.\n","*cohere: A library that allows interaction with Cohere's LLMs for natural language processing tasks.\n","*python-dotenv: Manages environment variables, making it easier to load sensitive information like API keys.\n","*pypdf: A library to read and process PDF files, allowing the bot to extract text from documents.\n","\n","\n","In this step, we're installing all the required libraries for building our Retrieval-Augmented Generation (RAG) QA bot. Each library serves a specific function, from interacting with language models to managing vector databases and handling PDF files."],"metadata":{"id":"6Qd1vwS0JcDJ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"GTqZ5TR5JAg6","collapsed":true},"outputs":[],"source":["!pip install langchain langchain_community langchain_core chromadb sentence_transformers cohere python-dotenv pypdf"]},{"cell_type":"markdown","source":["# **Importing Required Modules and Libraries**\n","\n","This cell imports all the necessary Python modules and libraries used throughout the code. Here's a brief overview:\n","\n","* Standard libraries: Modules like base64, logging, io, tempfile, os, and typing provide utility functions for encoding, logging, handling input/output streams, and managing temporary files.\n","*cohere: Connects to Cohere’s language models.\n","*dotenv: Loads environment variables from a .env file.\n","*langchain_core: Provides core components such as document handling, vector retrieval, runnable processes, and output parsing.\n","*langchain_community: Adds community-driven features like embedding generation using Hugging Face models and document storage using Chroma.\n","*google.colab.files: Facilitates file handling within Google Colab."],"metadata":{"id":"JMm5OvW8OIPb"}},{"cell_type":"code","source":["import base64\n","import logging\n","from typing import List\n","from io import BytesIO\n","import tempfile\n","import os\n","import cohere\n","from dotenv import load_dotenv\n","from langchain_core.documents import Document\n","from langchain_core.vectorstores import VectorStoreRetriever\n","from langchain_core.runnables.base import Runnable\n","from langchain_core.output_parsers import StrOutputParser\n","from langchain_core.runnables import RunnablePassthrough\n","from langchain_core.prompts import PromptTemplate\n","from langchain_core.prompt_values import StringPromptValue\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","from langchain_community.vectorstores import Chroma\n","from langchain_community.embeddings import HuggingFaceEmbeddings\n","from langchain_community.document_loaders import PyPDFLoader\n","from google.colab import files"],"metadata":{"id":"j9A_mQGgJq8l","executionInfo":{"status":"ok","timestamp":1726848204748,"user_tz":-330,"elapsed":623,"user":{"displayName":"Sumit Jha","userId":"04974617834705062972"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["# **Configuring Logging and Defining Prompt Template**\n","\n","This cell sets up logging and defines a prompt template for the RAG QA bot.\n","\n","* Logging Configuration: The logging is configured to track information and events throughout the program. The level is set to INFO, meaning all messages at this level and higher will be logged, helping with debugging and monitoring the bot's operations.\n","\n","* Prompt Template: A prompt template is created to guide the bot in generating responses. It instructs the model to use the provided context to answer the user's question. If the answer is unknown, the bot is directed to simply acknowledge that, avoiding any fabricated responses. This structure ensures that answers are helpful and relevant to the context given."],"metadata":{"id":"9Kwhf7LMOoaJ"}},{"cell_type":"code","source":["logging.basicConfig(level=logging.INFO)\n","logger = logging.getLogger(__name__)\n","\n","TEMPLATE = \"\"\"Use the following pieces of context to answer the question at the end.\n","If you don't know the answer, just say that you don't know, don't try to make up an answer.\n","Be helpful in your answer and be sure to reference the following context when possible.\n","\n","{context}\n","\n","Question: {question}\n","\n","Answer:\"\"\"\n","\n","prompt = PromptTemplate.from_template(TEMPLATE)"],"metadata":{"id":"hXL7lcbnJwF0","executionInfo":{"status":"ok","timestamp":1726848209531,"user_tz":-330,"elapsed":627,"user":{"displayName":"Sumit Jha","userId":"04974617834705062972"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["# **Setting Up Environment Variables and Cohere Client**\n","\n","This cell sets up the environment variable for the Cohere API key and initializes the Cohere client.\n","\n","* Environment Variable: The %env command assigns the Cohere API key to an environment variable. This allows the program to securely access sensitive information without hardcoding it into the script.\n","\n","* Loading Environment Variables: The load_dotenv() function loads environment variables from a .env file, making them accessible in the code.\n","\n","* Retrieving the API Key: The code retrieves the Cohere API key using os.getenv(). If the key is not found, it raises a ValueError, ensuring that the program does not proceed without the necessary credentials.\n","\n","* Cohere Client Initialization: Finally, a client instance for the Cohere API is created using the retrieved API key, allowing the bot to interact with Cohere’s language models."],"metadata":{"id":"k7rFY3OOPHcF"}},{"cell_type":"code","source":["%env COHERE_API_KEY=3teePOSAq4M3tIFOHKvrzLww6WfBGhwNp7AS1MkS\n","\n","load_dotenv()\n","COHERE_API_KEY = os.getenv(\"COHERE_API_KEY\")\n","if not COHERE_API_KEY:\n","    raise ValueError(\"Cohere API key not found in environment variables.\")\n","\n","co = cohere.Client(COHERE_API_KEY)"],"metadata":{"id":"DXAjgXgPJw1T"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Defining Functions for Document Handling and Retrieval**\n","\n","* get_embedding_function(): Initializes and returns a Hugging Face model for generating embeddings, logging the creation process.\n","\n","* get_embedding_retriever(splits: List[Document]): Embeds the document chunks using the embedding function and stores them in a Chroma vector store. It logs the embedding process and returns a retriever configured for similarity searches.\n","\n","* save_doc_locally(pdf_string: str): Decodes a base64-encoded PDF string and saves it as a BytesIO object. It logs the operation and checks for valid PDF content.\n","\n","* load_and_split_doc(pdf_file: BytesIO): Writes the PDF to a temporary file, then loads and splits it into manageable chunks using a specified text splitter. It ensures the temporary file is deleted afterward.\n","\n","* get_chain(retriever: VectorStoreRetriever, prompt: PromptTemplate): Constructs a processing chain that formats retrieved documents and passes them to the prompt template for answer generation.\n","\n","* format_docs(docs: List[Document]): Formats the content of document objects into a single string, separating them with newlines.\n","\n","* generate_answer_cohere(prompt_output: StringPromptValue): Sends the prompt output to Cohere to generate an answer, logging the generation process and handling potential errors.\n","\n","* upload_pdf(): Facilitates the uploading of a PDF file from the user's local system, encoding its content in base64 format for further processing. If no file is uploaded, it logs this information."],"metadata":{"id":"13K2_0JJPaod"}},{"cell_type":"code","source":["def get_embedding_function():\n","    logger.info(\"Creating new embedding function\")\n","    return HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n","\n","def get_embedding_retriever(splits: List[Document]) -> VectorStoreRetriever:\n","    logger.info(\"Embedding document chunks\")\n","    embedding_function = get_embedding_function()\n","    vectorstore = Chroma.from_documents(\n","        documents=splits,\n","        embedding=embedding_function,\n","        persist_directory=None\n","    )\n","    return vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5})\n","\n","def save_doc_locally(pdf_string: str) -> BytesIO:\n","    logger.info(\"Saving pdf document locally\")\n","    try:\n","        decoded_bytes = base64.b64decode(pdf_string)\n","        if decoded_bytes[:4] != b\"%PDF\":\n","            raise ValueError(\"Invalid PDF file received.\")\n","        return BytesIO(decoded_bytes)\n","    except Exception as e:\n","        logger.error(f\"Error saving PDF: {e}\")\n","        raise\n","\n","def load_and_split_doc(pdf_file: BytesIO) -> List[Document]:\n","    logger.info(\"Splitting pdf document into chunks\")\n","    try:\n","        with tempfile.NamedTemporaryFile(delete=False, suffix=\".pdf\") as temp_file:\n","            temp_file.write(pdf_file.getvalue())\n","            temp_file_path = temp_file.name\n","\n","        loader = PyPDFLoader(temp_file_path)\n","        splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50, add_start_index=True)\n","        return loader.load_and_split(text_splitter=splitter)\n","    finally:\n","        os.remove(temp_file_path)\n","\n","def get_chain(retriever: VectorStoreRetriever, prompt: PromptTemplate) -> Runnable:\n","    logger.info(\"Getting RAG chain\")\n","    return (\n","        {\n","            \"context\": retriever | format_docs,\n","            \"question\": RunnablePassthrough()\n","        }\n","        | prompt\n","        | generate_answer_cohere\n","        | StrOutputParser()\n","    )\n","\n","def format_docs(docs: List[Document]) -> str:\n","    return \"\\n\\n\".join(doc.page_content for doc in docs)\n","\n","def generate_answer_cohere(prompt_output: StringPromptValue) -> str:\n","    logger.info(\"Generating answer with Cohere\")\n","    try:\n","        response = co.generate(\n","            model=\"command-r-plus-04-2024\",\n","            prompt=prompt_output.to_string(),\n","            max_tokens=300,\n","            temperature=0.7\n","        )\n","        return response.generations[0].text.strip()\n","    except Exception as e:\n","        logger.error(f\"Error generating answer with Cohere: {e}\")\n","        raise\n","\n","def upload_pdf():\n","    uploaded = files.upload()\n","    if not uploaded:\n","        print(\"No file was uploaded.\")\n","        return None\n","\n","    file_name = next(iter(uploaded))\n","    pdf_content = uploaded[file_name]\n","    return base64.b64encode(pdf_content).decode('utf-8')"],"metadata":{"id":"4_XalJt3KCUG","executionInfo":{"status":"ok","timestamp":1726848211148,"user_tz":-330,"elapsed":3,"user":{"displayName":"Sumit Jha","userId":"04974617834705062972"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["# **PDF Processing Function**\n","\n","This cell defines the process_pdf function, which handles the entire workflow for processing a PDF document and generating a response based on a user’s question or a summary request.\n","\n","* Function Purpose: It takes a base64-encoded PDF string and an optional question, processing the PDF to either answer the question or summarize the document.\n","\n","* Logging: The function logs the start of the PDF processing and any subsequent actions, such as answer generation or summarization.\n","\n","* Saving the PDF: It first saves the PDF locally by calling save_doc_locally.\n","\n","* Loading and Splitting: The function then loads and splits the PDF into smaller chunks for easier processing using load_and_split_doc.\n","\n","* Embedding and Retrieval: It creates an embedding retriever for the document chunks through get_embedding_retriever.\n","\n","* Chain Setup: The function constructs a processing chain that will handle the interaction with the model using get_chain.\n","\n","* Question Handling: If a question is provided, it invokes the chain to generate an answer. If no question is given, it defaults to generating a summary of the document.\n","\n","* Error Handling: In case of any errors during processing, it logs the error and returns a user-friendly error message\n","\n"],"metadata":{"id":"4v5gABIlPzY2"}},{"cell_type":"code","source":["def process_pdf(pdf_string: str, question: str = None) -> str:\n","    logger.info(\"Processing PDF\")\n","    try:\n","        pdf_file = save_doc_locally(pdf_string)\n","        splits = load_and_split_doc(pdf_file)\n","        retriever = get_embedding_retriever(splits)\n","        chain = get_chain(retriever, prompt)\n","\n","        if question:\n","            logger.info(\"Generating answer\")\n","            return chain.invoke(question)\n","        else:\n","            logger.info(\"Generating summary\")\n","            return chain.invoke(\"Summarize the document\")\n","    except Exception as e:\n","        logger.error(f\"Error processing PDF: {e}\")\n","        return f\"An error occurred: {str(e)}\""],"metadata":{"id":"FBVo4uL5KIT0","executionInfo":{"status":"ok","timestamp":1726848211149,"user_tz":-330,"elapsed":3,"user":{"displayName":"Sumit Jha","userId":"04974617834705062972"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["# **Main Function for User Interaction**\n","\n","This cell defines the main function, which serves as the interactive entry point for the user to upload a PDF and engage with the RAG QA bot.\n","\n","* User Prompt: The function begins by prompting the user to upload a PDF file. It calls the upload_pdf function to handle this.\n","\n","* PDF Validation: If no PDF is uploaded, the function returns early, preventing further interaction.\n","\n","* Continuous Interaction: A while loop allows the user to choose between asking a question, summarizing the document, or exiting the program.\n","\n","* Input Handling:\n","\n","   * If the user enters 'e', the loop breaks, and the program exits.\n","   * If 'q' is entered, the user is prompted to input their question, which is then processed using the process_pdf function. The answer is printed.\n","   * If 's' is chosen, the function generates a summary of the document and prints it.\n","* Invalid Input Handling: If the user enters an invalid option, a message is displayed, prompting them to try again."],"metadata":{"id":"OmJmsD4nQJsa"}},{"cell_type":"code","source":["def main():\n","    print(\"Please upload a PDF file.\")\n","    pdf_string = upload_pdf()\n","    if pdf_string is None:\n","        return\n","\n","    while True:\n","        action = input(\"Enter 'q' to ask a question, 's' to summarize, or 'e' to exit: \").lower()\n","        if action == 'e':\n","            break\n","        elif action == 'q':\n","            question = input(\"Enter your question: \")\n","            answer = process_pdf(pdf_string, question)\n","            print(f\"Answer: {answer}\")\n","        elif action == 's':\n","            summary = process_pdf(pdf_string)\n","            print(f\"Summary: {summary}\")\n","        else:\n","            print(\"Invalid input. Please try again.\")"],"metadata":{"id":"i5xCNYlQKKa8","executionInfo":{"status":"ok","timestamp":1726848211799,"user_tz":-330,"elapsed":3,"user":{"displayName":"Sumit Jha","userId":"04974617834705062972"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["# **How to Access the RAG QA Bot**\n","\n","* Run the Code: Start by running the entire notebook. This will set up everything needed for the bot to function.\n","\n","* Upload a PDF: When prompted, upload a PDF file. This will be the document the bot will process.\n","\n","* Choose an Action:\n","\n","     * Ask a Question: Type 'q' and hit Enter. Then, enter your question about the PDF.\n","     * Summarize the Document: Type 's' and hit Enter to get a summary of the PDF.\n","     * Exit: Type 'e' to exit the program.\n","* Processing Time: On your first use, processing the PDF may take some time, especially if the document is large. Please be patient while the bot works.\n","\n","* Error Handling: If you see any errors, follow the messages to troubleshoot. You can always restart the process.\n","\n","Enjoy interacting with your RAG QA bot!\n","\n","\n","\n"],"metadata":{"id":"zI5v_PeNQjg-"}},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","    main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":181},"id":"p24QsPDCKMdU","outputId":"1bd2941f-42fc-4f6d-f87e-394375e2d995"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Please upload a PDF file.\n"]},{"data":{"text/html":["\n","     <input type=\"file\" id=\"files-ef23c33d-6d7f-4e04-b431-3e37b73b3530\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-ef23c33d-6d7f-4e04-b431-3e37b73b3530\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Saving f.pdf to f (2).pdf\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n","WARNING:chromadb.segment.impl.vector.local_hnsw:Number of requested results 5 is greater than number of elements in index 3, updating n_results = 3\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Summary: Football is a popular sport played at various levels, including high schools, colleges, and professional stadiums. The game involves running, passing, kicking, and bodily contact, with two teams of 11 players each attempting to move the ball across the opposing team's goal line to score points.\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"WGCnNZxOKOvT"},"execution_count":null,"outputs":[]}]}